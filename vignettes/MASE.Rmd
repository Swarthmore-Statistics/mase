---
title: "Model-Assisted Survey Estimators"
author: "Kelly McConville, Beck Tang, George Zhu, Shirley Cheung, Sida Li"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: mase.bib
vignette: >
  %\VignetteIndexEntry{Model-Assisted Survey Estimators}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r}
library(mase)
```


## Introduction

A common goal in survey sampling is to estimate finite population parameters. For instance, for a given company we might be interested in the total aggregate income of a given company as well as the mean income. Then these two quantities of interest can be written in the following manner: the total aggregate income is
$$
t_y = \sum_{i \in U} y_i,
$$
where $y_i$ respresents the income for each employer; or the mean 
$$
\mu_y = \frac{t_y}{N},
$$ 
 where $N$ is the total population size. 
 
 In the case where $y_i$ is a discrete or categorical measure (such as the marital status of the employees), we notice that $\mu_y$ would represent a proportion of those with such an attribute. 

`mase` provides several model-assisted estimators of the finite population total or mean.  All of the estimator in `mase` can be written as
$$
\hat{t}_y = \sum_{i \in s} \frac{y_i - \hat{y}_i}{\pi_i} + \sum_{i \in U} \hat{y}_i ,
$$

where for observation $i$, $\hat{y}_i$ is the predicted value of $y$ and $\pi_i = P(i \in S)$, the inclusion probability [@cas76; @sar92]. Different models for $\hat{y}_i$ would give us different model-assisted estimators.  The estimators in `mase`, along with the assisting model, necessary auxiliary data, and addional reference, are given in the following table:

```{r, echo=FALSE, message=FALSE}
library(readr)
estimatorsTable <- read_csv("estimatorsTable.csv")
knitr::kable(estimatorsTable)
```



* Add variance estimation.

* Try api dataset (population) in survey package to create examples.


## Contents

1. [Data](#getting-started)
    + [Data Requirements for mase](#data-mase)
    + [Example Dataset](#example-api)
    
2. [Survey Estimators](#survey-estimators)
    + [Horvitz-Thompson Estimator](#horvitz-thompson)
    + [Post-stratified Estimator](#post-stratified)
    + [Ratio Estimator](#ratio-estimator)
    + [Generalized Regression Estimator](#linear-regression) 
    + [Elastic Net Regression Estimator](#elastic-net) 
    
## Data




### Data Requirements for mase

* Discuss the required data for each estimator.  Make a table. 
    + Column: pop data type (raw, totals/means + N)
    + Row: Estimator type
    
May not need table since logistic greg and logistic gregElasticNet are the only ones that need raw data.    

### Example Dataset

```{r, echo=FALSE, message=FALSE}
library(survey)
data(api)
options(digits=2)
```

The survey package contains a census dataset of all California schools with at least 100 students, *apipop*, and several probability samples of the data.  We will use *apisrs*, a simple random sample without replacement of size 200, and *apistrat*, a stratified random sample of size 200. In these datasets, the primary attribute of interest is the Academic Performance Index.  Additional information about the schools and demographics of the schools are provided.  

For illustration purposes we will treat *apipop* as our finite population of interest and in various examples will use the samples *apisrs* and *apistrat*.
 We will assume that the attributes of interest are only known for the sample but that the auxiliary data are known for each school.  

Assume we want to estimate ??? in insert two quantities based on api and sch.wide or comp.imp.



## Survey Estimators

This section presents guidance on when each estimator is most appropriate and shows how to fit the estimators using mase.

### Horvitz-Thompson Estimator


* **Inputs**: 
* **Outputs**: 

If no auxiliary data are available, then $\hat{y}_i = 0$ in the model-assisted estimator of $t_y$ and the estimator simplifies to
$$
\hat{t}_y = \sum_{i \in s} \frac{y_i}{\pi_i},
$$
the survey-weighted sum of the sampled values [@hor52].  This estimator can be fit in mase using the following code:

```{r}
ht_srs <- horvitzThompson(y = apisrs$api00, pi = apisrs$pw^(-1))


ht_strat <- horvitzThompson(y = apistrat$api00, pi = apistrat$pw^(-1))

```

Then the Horvitz-Thompsons estimator for the average score is `r ht_srs$pop_mean` for the simple random sample and `r ht_strat$pop_mean` for the stratified sample.  Since $N$, the population size, was not specified, it was assumed to be $\sum_{i \in s} \pi_i^{-1}$.

The variance estimator can be found by adding the argument `var_est = TRUE` and specifying a method with `var_method`.

```{r}
ht_srs <- horvitzThompson(y = apisrs$api00, pi = apisrs$pw^(-1), var_est = TRUE, var_method = "HTSRS")

```

For the simple random sample, the variance of the HT estimator of the mean score is `r ht_srs$pop_mean_var`.  If the joint inclusions probabilites are known and positive (argument `pi2`), then the exact Horvitz-Thompson estimator of other single stage sampling designs can be found.  The variance can be estimated by selected one of the with-replacement variance estimators.

```{r}
ht_strat <- horvitzThompson(y = apisrs$api00, pi = apisrs$pw^(-1), var_est = TRUE, var_method = "HB")
```


### Post-stratified Estimator (Mickey)

(Reference: Calculating Post-Stgratified Proportions, John Williams, Department of Marketing, University of Otago, 2009)

It can often happen that we would like to put our population into categories but cannot perform this grouping unless the units are already sampled. To give a common example, a telephone interview cannot know before-hand how many male, female, or people of non-conforming gender would participate. The grouping can only be performed after the interview has taken place. Under these scenarios we consider our estimators post-stratified.

In particular, if there is a categorical auxiliary variable that is predictive of the study variable, then a post-stratified estimator could be more efficient than the Horvitz-Thompson estimator. Alternatively, it is often the case that a post-stratified estimator is better in a scenario where the size of the populations are uneven or fail to reflect reality. For instance, there might be a survey sampling of the amount of time men and women in favor of a certain policy. Suppose it turns out that disproportionately more men participated in the survey than did women. Then a conventional estimator that disregards the difference in proportions would fail to give the true mean, given that in reality there is a significant difference. 

Concretely, if we wanted to compute the average support rate of this policy for both men and women, our computation would often often have the following layout. Suppose that $N$ represents the total sample population size accounting for both men and women, $N_m$ for the number of participating men, $N_f$ for the number of participating women. Then we will also notate $\hat{\pi_m}$ for the percentage of men in favor of this policy in this survey and $\hat{\pi_f}$ for the percentage of women participating and in favor. 

The post stratified mean,
$$
\hat{\mu}_{\text{post}} = \frac{N_m}{N}  \hat{\pi}_m +  \frac{N_f}{N} \hat{\pi}_f,
$$
stands for our estimated support rate for the policy in the general public.

We can compute the mean of each population and the variance of the overall population. We first give general notations: let $y^h_j$ denote the value of the $j$-th unit in the category $h$; let 
$$
t_h =\sum _{j=1} ^ {N_h} y^h_j
$$
denote the sum of relevant interest (how many people in this group were in favor of this policy) in category $h$ (where in this context $h$ would take on two values to indicate whether the population under consideration is that of men or women). Then we have that the sample mean in stratum $h$  is 
$$
\overline{y}_h = \frac{\sum_{j\in S_h} y^h_j}{n_h},
$$
where the summation extends to all the samples in the stratum $h$ of our sample, and $n_h$ is the population of the stratum $h$. Note that the non-capitalized $n$ stands for population size of the sample. Similarly, the post-stratified estimate of the overall sample mean would be
$$
\overline{y}_{\text{post}} = \sum^H_{h=1} \frac{N_h}{N}\overline{y}_h, 
$$
where $H$ denotes the total number of strata in our sample. 

The variance computation is a little more tricky. The following formula applies only when three conditions are met: 
\begin{enumerate}
\item $N$ and $N_h$ are know; i.e., we know the overall population size. 

\item $n_h$ is reasonably large for all $h$. We should expect that $n_h >> 1$. 

\item $n$ is large, which is really a corollary of the previous condition.
#Find mathematical explanations for this...
\end{enumerate}
We have then the necessary assumptions for simple random sampling. 
$$
\hat{V}_{\text{post}} \approx (1-\frac{n}{N}) \sum^H _ {h=1} \frac{N_h}{N} \frac{s^2_h}{n},
$$
where $s^2_h$ is the sample variance in stratum $h$.

As it turns out, the desired quantities $N_h$ and $N$ are frequently unavailable. Therefore the package provides an alternate means of computing this variance. The methodology is somewhat complex, so the reader could do without following meticulously the mathematical exposition. 

In our example dataset, the binary categorical variable `awards` specifies whether a school is eligible for an awards program.   From the graph below, it appears that eligible schools have, on average, a higher api score.

```{r, echo=FALSE}
library(ggplot2)
ggplot(apistrat, aes(x = awards, y = api00)) + geom_boxplot()+ labs(x="Eligible for Awards Program?", y="API Scores for 2000") + theme_bw() 
```

To add the awards information, we need to include the sample values (`xsample`) and the population data (`xpop`). The following R scripts show three ways f achieving this.

```{r, message=FALSE}

#Raw data
ps_srs_r <- postStrat(y = apisrs$api00, xsample = apisrs$awards, xpop = apipop$awards, datatype = "raw", pi = apisrs$pw^(-1), var_est = TRUE, var_method = "HTSRS")


#Totals in each category 
pop_tots <- data.frame(table(apipop$awards))
ps_srs_t <- postStrat(y = apisrs$api00, xsample = apisrs$awards, xpop = pop_tots, datatype = "totals", pi = apisrs$pw^(-1), var_est = TRUE, var_method = "HTSRS")

#Means in each category
pop_means <- data.frame(table(apipop$awards)/length(apipop$awards))
ps_srs_m <- postStrat(y = apisrs$api00, xsample = apisrs$awards, xpop = pop_means, datatype = "means", pi = apisrs$pw^(-1), var_est = TRUE, var_method = "HTSRS")
#I need to discuss what the interpretation for these outputs is.
```



`r ps_srs_r$pop_mean`

### Ratio Estimator (Mickey)
Sometimes we are interested in the relationship between the average/expected behavior of two variables $X$ and $Y$. Then the variable of concern would be 
$$
r = \frac{\mu _Y}{\mu_X} = \frac{\sum_{i=1}^{N_Y} y_i}{\sum _{i=1} ^ {N_X} x_i}
$$


### Generalized Regression Estimator (Shirley)
The generalized regression estimator (GREG) can be used when the auxiliary data includes a mixture of both quantitative and categorical variables. It is expressed in the following form:
$$
\hat{\mu_{y}} = \frac{1}{N} \left(\sum_{i \in s}     
                \frac{y_{i}-\hat{m}(\boldsymbol{x}_{i})}{\pi_{i}} 
                + \sum_{i \in U}\hat{m}(\boldsymbol{x}_{i}) \right)
$$
where $\boldsymbol{x}_{i}$ is the auxiliary data, $\hat{m}(\boldsymbol{x}_{i})$ is the predicted value of $y$ given the auxiliary data, $y_{i}$ is the observed , $\pi_{i}$ is the inclusion probability (Cassel, Särndal, and Wretman 1976; Särndal, Swensson, and Wretman 1992), and $N$ is the size of the finite population. 

The exact form of the GREG is flexible. It varies depending on whether $y$ is quantitative or categorical and the availablity and relevancy of auxiliary data. Note that all aforementioned estimators are variations of the GREG. For example, in the case that no relevant auxiliary data exist, the $\hat{m}(x_{i})$ portions of our GREG equation simply equal zero, resulting in our Horvitz-Thompson estimator: 
$$
\hat{\mu_{y}} = \frac{1}{N} \left(\sum_{i \in s}     
                \frac{y_{i}}{\pi_{i}} \right)
$$
Mention linear vs. logistic regression?
provide code example of each 

To calculate api in our example dataset using GREG, we may apply the mase package, as follows:
```{r}
# GREG applied to simple random sample
greg_srs <- greg(y = apisrs$api00, 
                 xsample = apisrs[c("col.grad", "awards")],
                 xpop = apipop[c("col.grad", "awards")], 
                 pi = apisrs$pw^(-1), model = "linear")
greg_srs

# GREG applied to stratified sample
greg_strat <- greg(y = apistrat$api00, pi = apisrs$pw^(-1), model = "linear")
```



### Elastic Net Regression Estimator (Shirley)
same set of predictors as above, do model selection
hopefully we get smaller standard deviation

###References